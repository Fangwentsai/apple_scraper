#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç°¡åŒ–ç‰ˆæ¦‚è¦½æ¸¬è©¦å·¥å…·
æ¨¡æ“¬å¾ Apple ç”¢å“é é¢æå–è©³ç´°æ¦‚è¦½çš„éç¨‹
"""

import json
import requests
from bs4 import BeautifulSoup
import re
import time
from typing import Dict, List, Optional

class SimpleOverviewExtractor:
    def __init__(self):
        """åˆå§‹åŒ–ç°¡åŒ–ç‰ˆæ¦‚è¦½æå–å™¨"""
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0'
        }

    def extract_overview_from_url(self, product_url: str) -> str:
        """å¾ç”¢å“ URL æå–è©³ç´°æ¦‚è¦½"""
        try:
            print(f"ğŸ” æå–æ¦‚è¦½: {product_url[:80]}...")
            
            # ç™¼é€ HTTP è«‹æ±‚
            response = requests.get(product_url, headers=self.headers, timeout=30)
            response.raise_for_status()
            
            # è§£æ HTML
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # å˜—è©¦å¤šç¨®é¸æ“‡å™¨ä¾†æ‰¾åˆ°ç”¢å“æ¦‚è¦½å€åŸŸ
            overview_selectors = [
                '.rc-pdsection-mainpanel.column.large-9.small-12',
                '.rc-pdsection-mainpanel',
                '.pd-overview',
                '.pd-highlights',
                '[data-module-template="pd/overview"]',
                '.pd-overview-content',
                '.rf-pdp-overview',
                '.rf-pdp-highlights',
                '.rf-pdp-techspecs'
            ]
            
            overview_text = ""
            
            for selector in overview_selectors:
                try:
                    elements = soup.select(selector)
                    if elements:
                        print(f"âœ… æ‰¾åˆ°æ¦‚è¦½å€åŸŸ: {selector}")
                        
                        for element in elements:
                            text = element.get_text(strip=True, separator='\n')
                            if text and len(text.strip()) > 50:
                                overview_text += text.strip() + "\n\n"
                        
                        if overview_text:
                            break
                            
                except Exception as e:
                    print(f"é¸æ“‡å™¨ {selector} å¤±æ•—: {e}")
                    continue
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¦‚è¦½ï¼Œå˜—è©¦æå–ç”¢å“è¦æ ¼
            if not overview_text:
                print("ğŸ”„ å˜—è©¦æå–ç”¢å“è¦æ ¼...")
                overview_text = self.extract_product_specs(soup)
            
            # æ¸…ç†å’Œæ ¼å¼åŒ–æ–‡å­—
            if overview_text:
                overview_text = self.clean_overview_text(overview_text)
                print(f"âœ… æˆåŠŸæå–æ¦‚è¦½ ({len(overview_text)} å­—å…ƒ)")
                return overview_text
            else:
                print("âš ï¸ æœªèƒ½æå–åˆ°è©³ç´°æ¦‚è¦½")
                return ""
                
        except Exception as e:
            print(f"âŒ æå–æ¦‚è¦½å¤±æ•—: {e}")
            return ""

    def extract_product_specs(self, soup) -> str:
        """æå–ç”¢å“è¦æ ¼è³‡è¨Š"""
        specs_text = ""
        
        # å˜—è©¦å¤šç¨®è¦æ ¼é¸æ“‡å™¨
        spec_selectors = [
            '.rf-pdp-techspecs',
            '.pd-techspecs',
            '.rf-pdp-highlights',
            '.pd-highlights',
            '.rf-pdp-overview-content',
            '.pd-overview-content',
            '[data-module-template="pd/techspecs"]',
            '.rf-pdp-content',
            '.pd-features',
            '.product-features',
            '.tech-specs',
            '.product-highlights'
        ]
        
        for selector in spec_selectors:
            try:
                elements = soup.select(selector)
                if elements:
                    print(f"âœ… æ‰¾åˆ°è¦æ ¼å€åŸŸ: {selector}")
                    
                    for element in elements:
                        text = element.get_text(strip=True, separator='\n')
                        if text and len(text.strip()) > 30:
                            specs_text += text.strip() + "\n\n"
                    
                    if specs_text:
                        break
                        
            except Exception as e:
                print(f"è¦æ ¼é¸æ“‡å™¨ {selector} å¤±æ•—: {e}")
                continue
        
        return specs_text

    def clean_overview_text(self, text: str) -> str:
        """æ¸…ç†å’Œæ ¼å¼åŒ–æ¦‚è¦½æ–‡å­—"""
        if not text:
            return ""
        
        # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å’Œæ›è¡Œ
        text = re.sub(r'\n\s*\n', '\n', text)
        text = re.sub(r'\s+', ' ', text)
        
        # ç§»é™¤ä¸éœ€è¦çš„å…§å®¹
        unwanted_patterns = [
            r'åŠ å…¥è³¼ç‰©è»Š.*',
            r'ç«‹å³è³¼è²·.*',
            r'é¸æ“‡.*',
            r'Cookie.*',
            r'éš±ç§æ¬Š.*',
            r'ä½¿ç”¨æ¢æ¬¾.*',
            r'Â©.*Apple.*',
            r'å°ç£.*',
            r'Apple Store.*',
            r'è³¼è²·.*',
            r'æ¯”è¼ƒ.*',
            r'ç­è§£æ›´å¤š.*'
        ]
        
        for pattern in unwanted_patterns:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE)
        
        # æ ¼å¼åŒ–æ–‡å­—ï¼Œä¿ç•™é‡è¦çš„æ›è¡Œ
        lines = text.split('\n')
        formatted_lines = []
        
        for line in lines:
            line = line.strip()
            if line and len(line) > 5:  # éæ¿¾å¤ªçŸ­çš„è¡Œ
                formatted_lines.append(line)
        
        # é‡æ–°çµ„åˆï¼Œé™åˆ¶é•·åº¦
        formatted_text = '\n'.join(formatted_lines)
        
        if len(formatted_text) > 1000:
            formatted_text = formatted_text[:1000] + "..."
        
        return formatted_text.strip()

    def test_single_product(self, product: Dict) -> Dict:
        """æ¸¬è©¦å–®ä¸€ç”¢å“çš„æ¦‚è¦½æå–"""
        print(f"\nğŸ“¦ æ¸¬è©¦ç”¢å“: {product.get('ç”¢å“æ¨™é¡Œ', '')[:50]}...")
        
        product_url = product.get('ç”¢å“URL', '')
        if not product_url:
            print("âš ï¸ ç”¢å“æ²’æœ‰ URL")
            return product
        
        # æå–è©³ç´°æ¦‚è¦½
        detailed_overview = self.extract_overview_from_url(product_url)
        
        # æ›´æ–°ç”¢å“è³‡æ–™
        updated_product = product.copy()
        if detailed_overview:
            updated_product['ç”¢å“æ¦‚è¦½'] = detailed_overview
            print(f"âœ… æ¦‚è¦½æ›´æ–°æˆåŠŸ")
        else:
            print(f"âš ï¸ æ¦‚è¦½æå–å¤±æ•—ï¼Œä¿æŒåŸæœ‰å…§å®¹")
        
        return updated_product

    def load_sample_products(self, limit: int = 3) -> List[Dict]:
        """è¼‰å…¥ç¯„ä¾‹ç”¢å“"""
        try:
            with open('data/apple_refurbished_mac.json', 'r', encoding='utf-8') as f:
                products = json.load(f)
            
            # åªå–å‰å¹¾å€‹ç”¢å“é€²è¡Œæ¸¬è©¦
            sample_products = products[:limit]
            print(f"ğŸ“‚ è¼‰å…¥ {len(sample_products)} å€‹ç¯„ä¾‹ç”¢å“")
            return sample_products
            
        except Exception as e:
            print(f"âŒ è¼‰å…¥ç”¢å“è³‡æ–™å¤±æ•—: {e}")
            return []

def main():
    """ä¸»æ¸¬è©¦ç¨‹å¼"""
    print("ğŸ§ª ç°¡åŒ–ç‰ˆ Apple ç”¢å“æ¦‚è¦½æå–æ¸¬è©¦")
    print("=" * 60)
    
    extractor = SimpleOverviewExtractor()
    
    # è¼‰å…¥ç¯„ä¾‹ç”¢å“
    sample_products = extractor.load_sample_products(limit=3)
    
    if not sample_products:
        print("âŒ ç„¡æ³•è¼‰å…¥æ¸¬è©¦ç”¢å“")
        return
    
    updated_products = []
    
    for i, product in enumerate(sample_products, 1):
        print(f"\n{'='*60}")
        print(f"æ¸¬è©¦ç”¢å“ {i}/{len(sample_products)}")
        print(f"{'='*60}")
        
        # é¡¯ç¤ºåŸå§‹è³‡æ–™
        print(f"ğŸ“ åŸå§‹æ¦‚è¦½:")
        print(f"   {product.get('ç”¢å“æ¦‚è¦½', 'N/A')}")
        
        # æ¸¬è©¦æ¦‚è¦½æå–
        updated_product = extractor.test_single_product(product)
        updated_products.append(updated_product)
        
        # é¡¯ç¤ºæ›´æ–°å¾Œçš„æ¦‚è¦½
        new_overview = updated_product.get('ç”¢å“æ¦‚è¦½', '')
        if new_overview != product.get('ç”¢å“æ¦‚è¦½', ''):
            print(f"\nğŸ“ æ›´æ–°å¾Œæ¦‚è¦½:")
            if len(new_overview) > 200:
                print(f"   {new_overview[:200]}...")
            else:
                print(f"   {new_overview}")
        
        # é¿å…è«‹æ±‚éæ–¼é »ç¹
        if i < len(sample_products):
            print(f"\nâ³ ç­‰å¾… 3 ç§’...")
            time.sleep(3)
    
    # å„²å­˜æ¸¬è©¦çµæœ
    try:
        with open('data/simple_overview_test_result.json', 'w', encoding='utf-8') as f:
            json.dump(updated_products, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æ¸¬è©¦çµæœå·²å„²å­˜åˆ° data/simple_overview_test_result.json")
        
        # çµ±è¨ˆçµæœ
        improved_count = 0
        for original, updated in zip(sample_products, updated_products):
            if len(updated.get('ç”¢å“æ¦‚è¦½', '')) > len(original.get('ç”¢å“æ¦‚è¦½', '')):
                improved_count += 1
        
        print(f"\nğŸ“Š æ¸¬è©¦çµ±è¨ˆ:")
        print(f"   ç¸½æ¸¬è©¦ç”¢å“: {len(sample_products)}")
        print(f"   æ¦‚è¦½æ”¹å–„: {improved_count}")
        print(f"   æ”¹å–„ç‡: {improved_count/len(sample_products)*100:.1f}%")
        
    except Exception as e:
        print(f"âŒ å„²å­˜æ¸¬è©¦çµæœå¤±æ•—: {e}")

if __name__ == "__main__":
    main() 